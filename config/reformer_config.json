{
    "hidden_size" : 128,
    "emb_dim" : 128,
    "depth" : 12,
    "heads" : 4,
    "causal" : true,
    "n_hashes" : 8,
    "weight_tie" : true,
    "full_attn_thres" : 0,
    "use_scale_norm" : true,
    "max_position_embeddings" : 256
}
